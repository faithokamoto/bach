#!/usr/bin/env python3
"""Find segments where mates map in an allele-biased way.

For each non-filtered biallic SNP in a VCF,
for sample BAM files (assumed to be position-sorted/indexed) in a directory,
split mates by their SNP allele, and find segments with allele bias.

Scan SNP chromosome, counts ref/alt mates for all samples,
and finds consistent bias. Adjacent windows merged.

Heavily based on code written by ChatGPT.
"""

import argparse  # Command-line argument parsing
import csv  # CSV output
import math  # Floor operation
import os  # File operations
import pysam  # Reading BAMs and VCF
from scipy.stats import binomtest # Test significance of each biased site

from typing import Dict, List, Tuple

SAMPLE_BAMS = Dict[str, str]
"""Dictionary of {sample name: BAM file name} lookups."""
MATE_POS = Dict[str, List[int]]
"""Dictionary of {ref/alt: [bp mate positions]} for a given sample."""
PTR_POS = Dict[str, Dict[str, int]]
"""Dictionary of {start/end: {ref/alt: index}} pointers for a given sample."""
SEGMENT = Tuple[int, int, str, float]
"""Biased segment formatted as `(start, end, bias, p-value)`"""

MBP = 1_000_000
"""Mega base pair (1 million bp)."""

def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments with argparse."""
    parser = argparse.ArgumentParser(description='Find allele-biased segments. '
                                     'Compare mates of reads with SNP alleles.')
    
    parser.add_argument('-p', '--progress', metavar='#',
                        required=False, default=None, type=float,
                        help='Progress update frequency (# variants processed)')
    
    file_args = parser.add_argument_group('filepaths')
    file_args.add_argument('-v', '--vcf', help='Path to the SNP VCF')
    file_args.add_argument('-d', '--bam-dir', help='Directory with BAM files')
    file_args.add_argument('-o', '--output', help='Output CSV path')
    file_args.add_argument('-e', '--bam-ext', metavar='.<ext>',
                           required=False, default='.pos.sorted.bam',
                           help='Extension for BAMs (<sample>.ext) '
                                '[default=".pos.sorted.bam"]')
    
    # Sample/bias count arguments 
    bias_args = parser.add_argument_group('bias parameters')
    bias_args.add_argument('-O', '--max-opposite', metavar='0.*',
                           required=False, default=0, type=float,
                           help='Max share [0,0.5) of heterozygotes '
                                'with opposite bias [default=0]')
    bias_args.add_argument('-N', '--max-neutral', metavar='0.*',
                           required=False, default=0, type=float,
                           help='Max share [0,1) of heterozygotes '
                                'with 0 change [default=0]')
    bias_args.add_argument('-D', '--max-drop', metavar='#',
                           required=False, default=0, type=int,
                           help='Max count of homozygous/missing samples '
                                '[default=0]')
    
    # Window arguments
    window_args = parser.add_argument_group('window parameters')
    window_args.add_argument('-w', '--window-width', metavar='Mbp', type=float,
                             help='Window width, in Mbp, to scan with '
                                  '(Consecutive windows are merged)')
    window_args.add_argument('-s', '--move-step', metavar='Mbp',
                             required=False, default=None, type=float, 
                             help='Mbp step size, in Mbp. Use one of -s or -f')
    window_args.add_argument('-f', '--floor-to', metavar='Mbp',
                             required=False, default=None, type=float,
                             help='Mbp to floor read positions to in empirical '
                                  'window choice. Use one of -s or -f')
    return parser.parse_args()

def check_illogical_arguments(args: argparse.Namespace) -> None:
    """Run initial argument validity checks."""
    if args.progress is not None and args.progress <= 0:
        raise ValueError(f'Progress print frequency must be positive')
    
    if not os.path.isfile(args.vcf):
        raise FileNotFoundError(f'VCF {args.vcf} does not exist')
    if not os.path.isdir(args.bam_dir):
        raise FileNotFoundError(f'BAM dir {args.bam_dir} is not a directory')
    if not args.bam_ext.endswith('.bam'):
        raise ValueError(f'BAM file extension must end in ".bam"')
    
    if not (0 <= args.max_opposite < 0.5):
        raise ValueError(f'Max opposite samples share ({args.max_opposite}) '
                         'must be in [0, 0.5)')
    if not (0 <= args.max_opposite < 1):
        raise ValueError(f'Max neutral samples share ({args.max_neutral}) '
                         'must be in [0, 1)')
    
    if args.window_width < 1:
        raise ValueError(f'Window width {args.window_width}Mbp must be >=1Mbp')
    if args.window_width >= 50:
        raise ValueError(f'Window width {args.window_width}Mbp is too large. '
                         'Did you enter a value in bp instead of Mbp?')
    
    if (args.move_step is not None) + (args.floor_to is not None) != 1:
        raise ValueError(f'Use exactly one of -s or -f')
    if args.move_step:
        if args.move_step < 0.5:
            raise ValueError(f'Window step {args.move_step}Mbp '
                             'must be >=0.5Mbp.')
        if args.move_step >= 10:
            raise ValueError(f'Window step {args.move_step}Mbp is too large. '
                             'Did you enter a vaue in bp instead of Mbp?')
    if args.floor_to:
        if args.floor_to < 0.1:
            raise ValueError(f'Read floor threshould {args.floor_to}Mbp'
                             ' must be >=0.1Mbp.')
        if args.floor_to >= 10:
            raise ValueError(f'Read floor threshold {args.floor_to}Mbp '
                             'is too large. Did you enter a value in bp '
                             'instead of Mbp?')
    
def locate_bams(bam_dir: str, bam_ext: str, min_samples: int) -> SAMPLE_BAMS:
    """Find BAM files within given directory.

    Assumes that files are named <sample_name>.<ext>
    
    Parameters
    ----------
    bam_dir : str
        Directory to search within.
    bam_ext : str
        File extension to search for.
    min_samples : int
        The minimum number of samples which should have BAM files.
    
    Returns
    -------
    SAMPLE_BAMS
        BAM files found.
    """

    # Find files given parameters
    bams = {file.split('.')[0]: f'{bam_dir}/{file}'
            for file in os.listdir(bam_dir) if file.endswith(bam_ext)}
    # Verify file quantity
    if not bams:
        raise FileNotFoundError(f'No {bam_dir}/*{bam_ext}')
    if min_samples > len(bams):
        raise ValueError(f'At least {min_samples} sample(s) needed, but there '
                         f'are only {len(bams)} {bam_dir}/*{bam_ext} files')
    return bams

def get_allele_mate_pos(bam_path: str, chrom: str, pos: int, 
                        ref: str, alt: str) -> MATE_POS:
    """Get mate positions for reads supporting ref/alt alleles.

    Ignore reads with unmapped mates and reads that do not cover the SNP.
    BAM file must be position-sorted and indexed for fast random access.

    Parameters
    ----------
    bam_path : str
        Path to the BAM file.
    chrom : str
        Chromosome of the SNP.
    pos : int
        Position of the SNP in bp (0-indexed).
    ref : str
        Reference allele of the SNP.
    alt : str
        Alternate allele of the SNP.

    Returns
    -------
    MATE_POS
        Two lists of bp positions: mates of ref/alt-supporting reads.
    """

    ref_mates = []
    alt_mates = []
    with pysam.AlignmentFile(bam_path, 'rb') as bam_file:
        for read in bam_file.fetch(chrom, pos, pos + 1):
            # Only use mate pairs with high-quality mapping to the same chr
            if (read.is_secondary or read.mate_is_unmapped
                or read.reference_name != read.next_reference_name):
                continue
            
            ref_positions = read.get_reference_positions(full_length=True)
            # Handle deletions of the SNP position
            if pos not in ref_positions: continue
            
            base = read.query_sequence[ref_positions.index(pos)]
            if base == ref:
                ref_mates.append(read.next_reference_start)
            elif base == alt:
                alt_mates.append(read.next_reference_start)
    
    return {'ref': sorted(ref_mates), 'alt': sorted(alt_mates)}

def count_biased_samples(all_mates: Dict[str, MATE_POS], 
                         all_ptrs: Dict[str, PTR_POS],
                         cur_start: int, cur_end: int
                         ) -> Tuple[Dict[str, PTR_POS], Dict[str, int]]:
    """Count samples with read mate allele bias within a window.
    
    Assumes that all_mates is sorted, and that using
    all_ptrs to index into it would return reads <=
    the given endpoints, respectively.

    Parameters
    ----------
    all_mates : Dict[str, MATE_POS]
        `{sample_name: mate positions}` dictionary.
    all_ptrs : Dict[str, PTR_POS]
        `{sample_name: pointer positions}` dictionary.
    cur_start : int
        Starting position of the window in bp, 0-indexed.
    cur_end : int
        Ending position of the window in bp, 0-indexed.

    Returns
    -------
    all_ptrs : Dict[str, PTR_POS]
        Updated pointer dictionary.
    bias_counts : Dict[str, int]
        Number of samples with ref, alt, or neutral bias.
    """

    bias_counts = {'ref': 0, 'alt': 0, 'neutral': 0}
    for sample in all_mates.keys():
        mates = all_mates[sample]
        ptrs = all_ptrs[sample]

        # Adjust pointers to keep only mates within the current window
        for side, cutoff in {'start': cur_start, 'end': cur_end}.items():
            for allele in ['ref', 'alt']:
                i = ptrs[side][allele]
                while i < len(mates[allele]) and mates[allele][i] < cutoff:
                    i += 1
                ptrs[side][allele] = i

        # Read count within the window is just pointer distances
        ref_count = ptrs['end']['ref'] - ptrs['start']['ref']
        alt_count = ptrs['end']['alt'] - ptrs['start']['alt']

        # Update cross-sample trackers
        if ref_count > alt_count: bias_counts['ref'] += 1
        elif alt_count > ref_count: bias_counts['alt'] += 1
        else: bias_counts['neutral'] += 1

    return all_ptrs, bias_counts

def adjust_biased_segments(biased_segments: List[Tuple[int, int, str]],
                           bias_counts: Dict[str, int], max_opposite_num: float,
                           max_neutral_num: float, cur_start: int, cur_end: int
                           ) -> List[Tuple[int, int, str]]:
    """Adjust/add the latest biased segment to the list.

    If this segment has bias, and is overlapping/consecutive with
    a previous segment, they are merged. Otherwise new biased
    segments are added to the end of the list.
    
    Parameters
    ----------
    biased_segments : List[Tuple[int, int, str]]
        Segments with bias so far, as `(start, end, bias)`.
    bias_counts : Dict[str, int] 
        Number of samples with ref, alt, or neutral bias.
    max_opposite_num : float
        Maximum # of samples with opposite bias.
    max_neutral_num : float
        Maximum # of samples with neutral bias.
    cur_start : int
        Starting position of the window in bp, 0-indexed.
    cur_end : int
        Ending position of the window in bp, 0-indexed.
    
    Returns
    -------
    List[Tuple[int, int, str]]
        Updated list of biased segments.
    """

    if (min(bias_counts['ref'], bias_counts['alt']) <= max_opposite_num
        and bias_counts['neutral'] <= max_neutral_num):
        bias = 'ref' if bias_counts['ref'] > bias_counts['alt'] else 'alt'
        # Extend previous segment if adjacent/overlapping and same bias
        if (biased_segments and biased_segments[-1][1] >= cur_start 
            and biased_segments[-1][2] == bias):
            biased_segments[-1] = (biased_segments[-1][0], cur_end, bias)
        else: biased_segments.append((cur_start, cur_end, bias))
    return biased_segments

def find_biased_segments(all_mates: Dict[str, MATE_POS], window_width: int,
                         window_starts: List[int], max_opposite: float,
                         max_neutral: float) -> List[Tuple[int, int, str]]:
    """Scan for read mate allele-biased segments.

    Scans the chromosome in 5Mbp steps to identify segments
    with consistent allele bias across samples.
    Excludes segments containing the SNP itself.

    Parameters
    ----------
    all_mates : Dict[str, MATE_POS]
        `{sample_name: mate positions}` dictionary.
    window_width : int
        Window width, in bp, to use during scanning.
    window_starts : List[int]
        Starting locations for windows to test.
    max_opposite : float
        Maximum % of samples with opposite bias.
    max_neutral : float
        Maximum % of samples without bias.

    Returns
    -------
    List[Tuple[int, int, str]]
        List of biased segments, each as `(start, end, bias)`.
    """

    max_opposite_num = max_opposite * len(all_mates)
    max_neutral_num = max_neutral * len(all_mates)

    biased_segments = []
    # All pointers start at the beginning of the list
    all_ptrs = {sample: {'start': {'ref': 0, 'alt': 0}, 
                         'end': {'ref': 0, 'alt': 0}}
                         for sample in all_mates.keys()}

    for cur_start in window_starts:
        cur_end = cur_start + window_width

        # Count bias within this segment
        all_ptrs, bias_counts = count_biased_samples(
            all_mates, all_ptrs, cur_start, cur_end)
        
        # Determine whether/how to use this sgement in biased_segments
        biased_segments = adjust_biased_segments(
            biased_segments, bias_counts, max_opposite_num, 
            max_neutral_num, cur_start, cur_end)
    
    return biased_segments

def add_binomial_pvalue(all_mates: Dict[str, MATE_POS],
                        biased_segments: List[Tuple[int, int, str]]
                        ) -> List[SEGMENT]:
    """Calculate binomial test p-values for allele-biased segments.

    Parameters
    ----------
    all_mates : Dict[str, MATE_POS]
        `{sample_name: mate positions}` dictionary.
    biased_segments : List[Tuple[int, int, str]]
        Output of `scan_for_biased_segments`, formatted as `(start, end, bias)`.

    Returns
    -------
    List[SEGMENT]
        List of biased segments, formatted as `(start, end, bias, p-value)`.
    """

    results = []

    # All pointers start at the beginning of the list
    all_ptrs = {sample: {'start': {'ref': 0, 'alt': 0}, 
                         'end': {'ref': 0, 'alt': 0}}
                         for sample in all_mates.keys()}

    for start, end, bias in biased_segments:
        ref_total, alt_total = 0, 0
        sample_counts = []

        for sample in all_mates.keys():
            mates = all_mates[sample]
            ptrs = all_ptrs[sample]

            # Adjust pointers to include only mates within the segment
            for side, cutoff in {"start": start, "end": end}.items():
                for allele in ["ref", "alt"]:
                    i = ptrs[side][allele]
                    while i < len(mates[allele]) and mates[allele][i] < cutoff:
                        i += 1
                    ptrs[side][allele] = i

            # Read count within the window is just pointer distances
            ref_count = ptrs["end"]["ref"] - ptrs["start"]["ref"]
            alt_count = ptrs["end"]["alt"] - ptrs["start"]["alt"]

            # Keep track of counts per sample for filtering
            if ref_count > alt_count:
                sample_counts.append(("ref", ref_count, alt_count))
                ref_total += 1
            elif alt_count > ref_count:
                sample_counts.append(("alt", ref_count, alt_count))
                alt_total += 1

        # Binomial test for this many samples having consistent bias
        k = max(ref_total, alt_total)  
        n = ref_total + alt_total
        p_value = binomtest(k, n, p=0.5, alternative="two-sided").pvalue

        results.append((start, end, bias, p_value))

    return results

def run_pipeline(bams: SAMPLE_BAMS, max_opposite: float, max_neutral: float,
                 max_drop: int, record: pysam.VariantRecord, chr_length: int,
                 window_width: int, move_step: int = None,
                 floor_to: int = None) -> List[SEGMENT]:
    """Run mate allele biased segment detection pipeline for a variant.
    
    Parameters
    ----------
    bams : SAMPLE_BAMS
        BAM files to use.
    max_opposite : float
        Maximum % of samples with opposite bias.
    max_neutral : float
        Maximum % of samples without bias.
    max_drop : int
        Maximum # of samples to drop.
    record : pysam.VariantRecord
        Variant to scan for.
    chr_length : int
        Length of this variant's chromosome.
    window_width : int
        Window width, in bp, to use during scanning.
    move_step : int [ default None ]
        Window step, in bp, to use during scanning.
        If None, then read rounding will be used.
    floor_to : int [ default None ]
        What to round read positions to, in Mbp, for window start.
        If None, then window step will be used.

    Returns
    -------
    List[SEGMENT]
        Biased segments found, or None if the variant wasn't tested.
    """

    # Only use high-quality biallelic variants
    if not record.filter or len(record.alts) != 1: return None

    chrom, ref, alt = record.chrom, record.ref, record.alts[0]
    # Convert from 1-index VCF to 0-indexed BAM
    snp_pos = record.pos - 1

    # Only use SNPs
    if len(ref) > 1 or len(alt) > 1: return None

    # Only use heterozygous genotypes
    is_het = {name: s['GT'][0] != s['GT'][1]
              for name, s in record.samples.items()}
    if len(bams) - sum(is_het.values()) > max_drop: return None

    mates = {sample: get_allele_mate_pos(file, chrom, snp_pos, ref, alt)
                for sample, file in bams.items() if is_het[sample]}

    # Create lists of window starts for the chosen method
    if move_step is not None:
        # Steps of move_step along chromosome
        window_starts = range(0, chr_length - window_width + 1, move_step)
    else:
        window_starts = set()

        for sample_mates in mates.values():
            for allele_mates in sample_mates.values():
                for pos in allele_mates:
                    # Floor mate position with floor_to precision
                    window_starts.add(math.floor(pos / floor_to) * floor_to)
        # Convert to sorted list
        window_starts = sorted(window_starts)

    window_starts = [pos for pos in window_starts if 
                    # Filter out windows which contain the SNP itself
                    not pos <= snp_pos <= pos + window_width]
    
    biased_segments = find_biased_segments(
        mates, window_width, window_starts, max_opposite, max_neutral)
    
    return add_binomial_pvalue(mates, biased_segments)

if __name__ == '__main__':
    args = parse_arguments()
    check_illogical_arguments(args)
    # At least one more than max_drop samples are needed for worst-case analysis
    bams = locate_bams(args.bam_dir, args.bam_ext, args.max_drop + 1)
    print(f'{len(bams)} BAMs found in {args.bam_dir}/<sample>{args.bam_ext}')

    # Convert window arguments to bp whole numbers
    window_width = int(args.window_width * MBP)
    move_step = None if args.move_step is None else int(args.move_step * MBP)
    floor_to = None if args.floor_to is None else int(args.floor_to * MBP)
    
    # Main logic
    with open(args.output, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        # Header row
        writer.writerow(['CHROM', 'SNP_POS', 'SNP_ID',
                         'BIAS_START_MBP', 'BIAS_END_MBP', 'BIAS', 'P_VALUE'])

        with pysam.VariantFile(args.vcf) as vcf:
            # Ignore VCF samples which don't have BAMs
            vcf.subset_samples(bams.keys())

            # Progress trackers
            total_variants = 0
            variants_dropped = 0
            total_biased_segments = 0

            for record in vcf:
                total_variants += 1
                chr_length = vcf.header.contigs[record.chrom].length

                # Get results for this variant
                biased_segments = run_pipeline(
                    bams, args.max_opposite, args.max_neutral,
                    args.max_drop, record, chr_length, 
                    window_width, move_step, floor_to)
                
                if biased_segments is None: variants_dropped += 1
                else:
                    total_biased_segments += len(biased_segments)
                
                    # Write results for this variant
                    for start, end, bias, p in biased_segments:
                        writer.writerow([record.pos, record.id, record.chrom,
                                        int(start/MBP), int(end/MBP), bias, p])
                
                if (args.progress is not None 
                    and total_variants % args.progress == 0):
                    print(f'{total_variants} variants processed: '
                          f'{total_variants - variants_dropped} tested, '
                          f'{variants_dropped} dropped')
    
        print(f'{total_variants} variants read from VCF')
        print(f'{total_variants - variants_dropped} non-filtered biallelic SNPs'
              f' with >={len(bams) - args.max_drop} heterozygotes tested')
        print(f'{variants_dropped} other variants dropped')
        print(f'{total_biased_segments} biased segments written to CSV')